{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e980a47a",
   "metadata": {},
   "source": [
    "**Inicialização**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9581fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando bibliotecas\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df2cf6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fazendo a leitura do arquivo csv\n",
    "try:\n",
    "    df = pd.read_csv('Downloads\\Churn.csv')\n",
    "except:\n",
    "    df = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b19f83",
   "metadata": {},
   "source": [
    "**Analisando os dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c243843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificando as 5 primieras linhas do dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "726a2d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3.0</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "9995     5.0       0.00              2          1               0   \n",
       "9996    10.0   57369.61              1          1               1   \n",
       "9997     7.0       0.00              1          0               1   \n",
       "9998     3.0   75075.31              2          1               0   \n",
       "9999     NaN  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificando as 5 ultimas linhas do dataframe\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "351fdb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# analisando informações do dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a30f63de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.7963\n",
       "1    0.2037\n",
       "Name: Exited, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificando a quantidade de pessoas que ficaram e sairam\n",
    "df['Exited'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598a7725",
   "metadata": {},
   "source": [
    "**Tratamento dos dados / Pré-processamento**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd657162",
   "metadata": {},
   "source": [
    "Podemos observar colunas que não devem possuir relevancia para o treinamento do modelo:`RowNumber, CustomerId, Surname`.\n",
    "Vamos remove-las! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aeae4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminando colunas que não devem influenciar no treinamento\n",
    "df = df.drop(['RowNumber','CustomerId','Surname'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0036c0fb",
   "metadata": {},
   "source": [
    "Vimos que existem valores nulos no nosso data frame na coluna `Tenure`, vamos tratar disso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f322fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0909"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificando a média dos dados ausentes\n",
    "df['Tenure'].isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05bebf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# substituindo os valores ausentes pela mediana\n",
    "df['Tenure'] = df['Tenure'].fillna(df['Tenure'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0848038e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verifiando se a duplicatas\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3d6b6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CreditScore      10000 non-null  int64  \n",
      " 1   Geography        10000 non-null  object \n",
      " 2   Gender           10000 non-null  object \n",
      " 3   Age              10000 non-null  int64  \n",
      " 4   Tenure           10000 non-null  float64\n",
      " 5   Balance          10000 non-null  float64\n",
      " 6   NumOfProducts    10000 non-null  int64  \n",
      " 7   HasCrCard        10000 non-null  int64  \n",
      " 8   IsActiveMember   10000 non-null  int64  \n",
      " 9   EstimatedSalary  10000 non-null  float64\n",
      " 10  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(6), object(2)\n",
      "memory usage: 859.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# verificando as informações do dataframe\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "877fe41d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# codificando todo o dataframe com OHE\n",
    "df_ohe = pd.get_dummies(df, drop_first = True)\n",
    "\n",
    "# verificando o tamanho da tabela \n",
    "df_ohe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ef5a813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42     2.0       0.00              1          1   \n",
       "1          608   41     1.0   83807.86              1          0   \n",
       "2          502   42     8.0  159660.80              3          1   \n",
       "3          699   39     1.0       0.00              2          0   \n",
       "4          850   43     2.0  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1        101348.88       1                  0   \n",
       "1               1        112542.58       0                  0   \n",
       "2               0        113931.57       1                  0   \n",
       "3               0         93826.63       0                  0   \n",
       "4               1         79084.10       0                  0   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificando as 5 primieras linhas do novo dataframe\n",
    "df_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4001f6dd",
   "metadata": {},
   "source": [
    "**Separando o conjuntos de dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b3b36b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separando conjunto de caracteristicas do alvo\n",
    "features = df_ohe.drop('Exited', axis=1)\n",
    "target = df_ohe['Exited']\n",
    "\n",
    "# dividir os dados em treinamento e teste\n",
    "features_train, features_test, target_train, target_test = train_test_split(\n",
    "    features, target, test_size=0.25, random_state=12345)\n",
    "\n",
    "# dividir os dados de treinamento em treinamento e validação\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features_train, target_train, test_size=0.25, random_state=12345)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36214b2",
   "metadata": {},
   "source": [
    "**Escalabilidade das características**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fcc67c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# é utilizado para desabilitar um aviso que pode aparecer quando as variáveis \n",
    "# features_train, features_valid e features_test são modificadas.\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# separando as colunas numéricas\n",
    "numeric = ['CreditScore','Age','Tenure','Balance','NumOfProducts','EstimatedSalary']\n",
    "\n",
    "# criando uma instância da classe StandardScaler() para ajustar os dados\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# ajustando o scaler apenas com os dados numéricos do conjunto de treinamento\n",
    "scaler.fit(features_train[numeric])\n",
    "\n",
    "# aplicando o scaler ajustado aos dados numéricos dos conjuntos de treinamento, validação e teste\n",
    "# com o scaler aplicado, as colunas numéricas serão escalonadas para o intervalo de valores [-1, 1].\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "features_test[numeric] = scaler.transform(features_test[numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9473778c",
   "metadata": {},
   "source": [
    "**Modelo - Regressão Logística**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64a52610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score = 0.31640625\n",
      "auc roc = 0.789968315437423\n"
     ]
    }
   ],
   "source": [
    "# criação de um modelo de Regressão Logística\n",
    "model_logistic_regression = LogisticRegression(random_state=12345, solver='liblinear')\n",
    "\n",
    "# treinamento do modelo utilizando o conjunto de dados de treinamento\n",
    "model_logistic_regression.fit(features_train, target_train)\n",
    "\n",
    "# realização de predições no conjunto de dados de validação\n",
    "valid_predicted = model_logistic_regression.predict(features_valid)\n",
    "\n",
    "# cálculo das probabilidades para cada classe no conjunto de dados de validação\n",
    "probabilities_valid = model_logistic_regression.predict_proba(features_valid)\n",
    "\n",
    "# extração das probabilidades para a classe positiva (classe 1)\n",
    "probabilities_valid_one = probabilities_valid[:,1]\n",
    "\n",
    "# impressão das métricas de avaliação do modelo no conjunto de dados de validação\n",
    "print('f1 score =',f1_score(target_valid,valid_predicted))\n",
    "print('auc roc =', roc_auc_score(target_valid,probabilities_valid_one))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3d04f9",
   "metadata": {},
   "source": [
    "**Modelo - Árvore de Decisão**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45df9a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A melhor profundidade é 14\n",
      "f1 score de validação de 0.54\n",
      "roc_auc score de validação de 0.72\n"
     ]
    }
   ],
   "source": [
    "# define variáveis iniciais\n",
    "best_depth = 0\n",
    "best_score_train = 0.0\n",
    "best_score_valid = 0.0\n",
    "\n",
    "# loop para avaliar a performance do modelo em diferentes profundidades\n",
    "for depth in range(1, 15):\n",
    "    \n",
    "    # cria modelo com profundidade atual do loop\n",
    "    model_decision_tree = DecisionTreeClassifier(random_state=12345,\n",
    "                                                 max_depth=depth)\n",
    "    \n",
    "    # treinamento do modelo utilizando o conjunto de dados de treinamento\n",
    "    model_decision_tree.fit(features_train, target_train)\n",
    "    \n",
    "    # realização de predições no conjunto de dados de validação\n",
    "    predicted_valid = model_decision_tree.predict(features_valid)\n",
    "    \n",
    "    # cálculo das probabilidades para cada classe no conjunto de dados de validação\n",
    "    probabilities_valid = model_decision_tree.predict_proba(features_valid)\n",
    "    \n",
    "    # extração das probabilidades para a classe positiva (classe 1)\n",
    "    probabilities_valid_one = probabilities_valid[:,1]\n",
    "\n",
    "    # avalia desempenho do modelo nos conjuntos de treinamento e validação\n",
    "    score_f1 = f1_score(target_valid, predicted_valid)\n",
    "    score_roc_auc = roc_auc_score(target_valid, probabilities_valid_one)\n",
    "\n",
    "    # atualiza variáveis de melhor performance encontrada\n",
    "    if score_f1 > best_score_valid:\n",
    "        best_depth = depth\n",
    "        best_score_roc_auc = score_roc_auc\n",
    "        best_score_f1 = score_f1\n",
    "\n",
    "# imprime melhor f1 e roc auc correspondentes\n",
    "print(\n",
    "    f\"A melhor profundidade é {best_depth}\\nf1 score de validação de {best_score_f1:.2f}\\nroc_auc score de validação de {best_score_roc_auc:.2f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab301fa0",
   "metadata": {},
   "source": [
    "**Modelo - Floresta Aleatória**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f5898a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor profundidade: 13\n",
      "Melhor n_estimators: 9\n",
      "F1 score de validação: 0.59\n",
      "ROC AUC score de validação: 0.85\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# define variáveis iniciais\n",
    "best_depth = 0\n",
    "best_est = 0\n",
    "best_score_train = 0.0\n",
    "best_score_valid = 0.0\n",
    "best_score_f1 = 0.0\n",
    "best_score_roc_auc = 0.0\n",
    "\n",
    "# loop externo para avaliar a performance do modelo em diferentes profundidades máximas\n",
    "for depth in range(1, 20):\n",
    "\n",
    "    # loop interno para avaliar a performance do modelo em diferentes número de estimadores\n",
    "    for est in range(1, 10):\n",
    "\n",
    "        # cria modelo com profundidade e número de estimadores atual do loop\n",
    "        model_random_forest = RandomForestClassifier(random_state=12345,\n",
    "                                                     n_estimators=est,\n",
    "                                                     max_depth=depth)\n",
    "\n",
    "        # treinamento do modelo utilizando o conjunto de dados de treinamento\n",
    "        model_random_forest.fit(features_train, target_train)\n",
    "\n",
    "        # realização de predições no conjunto de dados de validação\n",
    "        predicted_valid = model_random_forest.predict(features_valid)\n",
    "\n",
    "        # cálculo das probabilidades para cada classe no conjunto de dados de validação\n",
    "        probabilities_valid = model_random_forest.predict_proba(features_valid)\n",
    "\n",
    "        # extração das probabilidades para a classe positiva (classe 1)\n",
    "        probabilities_valid_one = probabilities_valid[:, 1]\n",
    "\n",
    "        # avalia desempenho do modelo nos conjuntos de treinamento e validação\n",
    "        score_f1 = f1_score(target_valid, predicted_valid)\n",
    "        score_roc_auc = roc_auc_score(target_valid, probabilities_valid_one)\n",
    "\n",
    "        # verifica se o resultado atual é melhor do que o melhor encontrado até o momento\n",
    "        if score_f1 > best_score_f1:\n",
    "            best_depth = depth\n",
    "            best_est = est\n",
    "            best_score_train = model_random_forest.score(\n",
    "                features_train, target_train)\n",
    "            best_score_valid = model_random_forest.score(\n",
    "                features_valid, target_valid)\n",
    "            best_score_f1 = score_f1\n",
    "            best_score_roc_auc = score_roc_auc\n",
    "\n",
    "# imprime melhor f1 e roc auc correspondentes\n",
    "print(\n",
    "    f\"Melhor profundidade: {best_depth}\\nMelhor n_estimators: {best_est}\\nF1 score de validação: {best_score_f1:.2f}\\nROC AUC score de validação: {best_score_roc_auc:.2f}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e7b0b4",
   "metadata": {},
   "source": [
    "**Ajuste de ponderação da classe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73ef62a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score = 0.5271317829457365\n",
      "auc roc = 0.8216581587748636\n"
     ]
    }
   ],
   "source": [
    "# cria modelo com profundidade e número de estimadores e usando class_weight\n",
    "model_random_forest = RandomForestClassifier(random_state=12345,\n",
    "                                             n_estimators=est,\n",
    "                                             max_depth=depth,\n",
    "                                             class_weight='balanced')\n",
    "\n",
    "# treinamento do modelo utilizando o conjunto de dados de treinamento\n",
    "model_random_forest.fit(features_train, target_train)\n",
    "\n",
    "# realização de predições no conjunto de dados de validação\n",
    "predicted_valid = model_random_forest.predict(features_valid)\n",
    "\n",
    "# cálculo das probabilidades para cada classe no conjunto de dados de validação\n",
    "probabilities_valid = model_random_forest.predict_proba(features_valid)\n",
    "\n",
    "# extração das probabilidades para a classe positiva (classe 1)\n",
    "probabilities_valid_one = probabilities_valid[:, 1]\n",
    "\n",
    "# avalia desempenho do modelo nos conjuntos de treinamento e validação\n",
    "score_f1 = f1_score(target_valid, predicted_valid)\n",
    "score_roc_auc = roc_auc_score(target_valid, probabilities_valid_one)\n",
    "\n",
    "# impressão das métricas de avaliação do modelo no conjunto de dados de validação\n",
    "print('f1 score =', score_f1)\n",
    "print('auc roc =', score_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b10308e",
   "metadata": {},
   "source": [
    "**upsample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecbd8046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.7963\n",
       "1    0.2037\n",
       "Name: Exited, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificando classe majoritária e minoritária\n",
    "df['Exited'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbe2ec33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15723, 11)\n",
      "(15723,)\n"
     ]
    }
   ],
   "source": [
    "# define a função upsample que faz a reamostragem das observações da classe minoritária aumentando sua\n",
    "# proporção em relação à classe majoritária. a função recebe três parâmetros: features (variáveis explicativas),\n",
    "# target (variável target) e repeat (fator de aumento da classe minoritária).\n",
    "def upsample(features, target, repeat):\n",
    "\n",
    "    # cria quatro variáveis: features_zeros (observações da classe majoritária), features_ones\n",
    "    # (observações da classe minoritária), target_zeros (alvo da classe majoritária), target_ones\n",
    "    # (alvo da classe minoritária).\n",
    "    features_zeros = features_train[target_train == 0]\n",
    "    features_ones = features_train[target_train == 1]\n",
    "    target_zeros = target_train[target_train == 0]\n",
    "    target_ones = target_train[target_train == 1]\n",
    "\n",
    "    # concatena as features_zeros com features_ones repetidas repeat vezes e faz o mesmo para target_zeros e target_ones.\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "\n",
    "    # embaralha as features e targets resultantes e retorna como a saída da função.\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled,\n",
    "                                                   target_upsampled,\n",
    "                                                   random_state=12345)\n",
    "\n",
    "    # a função retorna duas variáveis: features_upsampled (variáveis explicativas reamostradas), target_upsampled\n",
    "    #(variável target reamostrada)\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "\n",
    "# executa a função upsample com os parâmetros features_train, target_train e 10 e armazena as variáveis resultantes\n",
    "# features_upsampled, target_upsampled.\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train,\n",
    "                                                10)\n",
    "\n",
    "# imprime as dimensões das variáveis resultantes\n",
    "print(features_upsampled.shape)\n",
    "print(target_upsampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00810e1",
   "metadata": {},
   "source": [
    "**Treinando modelo usando o upsample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9a1c222a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score = 0.5879194630872483\n",
      "auc roc = 0.8293548671008626\n"
     ]
    }
   ],
   "source": [
    "# criando modelo\n",
    "model_random_forest = RandomForestClassifier(random_state=12345,\n",
    "                                             n_estimators=est,\n",
    "                                             max_depth=depth)\n",
    "\n",
    "# treinamento do modelo utilizando features_upsampled (variáveis explicativas reamostradas), target_upsampled\n",
    "# (variável target reamostrada)\n",
    "model_random_forest.fit(features_upsampled, target_upsampled)\n",
    "\n",
    "# realização de predições no conjunto de dados de validação\n",
    "predicted_valid = model_random_forest.predict(features_valid)\n",
    "\n",
    "# cálculo das probabilidades para cada classe no conjunto de dados de validação\n",
    "probabilities_valid = model_random_forest.predict_proba(features_valid)\n",
    "\n",
    "# extração das probabilidades para a classe positiva (classe 1)\n",
    "probabilities_valid_one = probabilities_valid[:, 1]\n",
    "\n",
    "# avalia desempenho do modelo nos conjuntos de treinamento e validação\n",
    "score_f1 = f1_score(target_valid, predicted_valid)\n",
    "score_roc_auc = roc_auc_score(target_valid, probabilities_valid_one)\n",
    "\n",
    "# impressão das métricas de avaliação do modelo no conjunto de dados de validação\n",
    "print('f1 score =', score_f1)\n",
    "print('auc roc =', score_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a04b329",
   "metadata": {},
   "source": [
    "**Teste final**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "029a8027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor est: 10\n",
      "Melhor depth: 5\n",
      "Melhor f1 score: 0.6279969064191803\n",
      "Melhor roc auc score: 0.851155501652755\n"
     ]
    }
   ],
   "source": [
    "# lista de valores para est e depth que desejamos testar de forma mais eficiente\n",
    "est_values = [5, 10]\n",
    "depth_values = [5, 10, 15, 20]\n",
    "\n",
    "# define variáveis iniciais\n",
    "best_score_f1 = 0\n",
    "best_score_roc_auc = 0\n",
    "best_est = 0\n",
    "best_depth = 0\n",
    "\n",
    "# loop aninhado para testar diferentes valores para est e depth\n",
    "for est in est_values:\n",
    "    for depth in depth_values:\n",
    "\n",
    "        # concatenando os dados de treinamento e validação das features\n",
    "        features_train_final = pd.concat([features_train] + [features_valid])\n",
    "\n",
    "        # concatenando os dados de treinamento e validação do target\n",
    "        target_train_final = pd.concat([target_train] + [target_valid])\n",
    "\n",
    "        # criando o modelo de RandomForestClassifier com os valores de est e depth correspondentes\n",
    "        # estabelecendo o parâmetro class_weight como \"balanced\"\n",
    "        model_random_forest = RandomForestClassifier(random_state=12345,\n",
    "                                                     n_estimators=est,\n",
    "                                                     max_depth=depth,\n",
    "                                                     class_weight='balanced')\n",
    "        \n",
    "        # treinamento do modelo utilizando features_upsampled (variáveis explicativas reamostradas), target_upsampled\n",
    "        # (variável target reamostrada)\n",
    "        model_random_forest.fit(features_upsampled, target_upsampled)\n",
    "        \n",
    "        # treinando o modelo com os dados de treinamento e validação concatenados\n",
    "        model_random_forest.fit(features_train_final, target_train_final)\n",
    "\n",
    "        # realizando previsões com os dados de teste\n",
    "        predicted_test = model_random_forest.predict(features_test)\n",
    "\n",
    "        # obtendo as probabilidades das previsões com os dados de teste\n",
    "        probabilities_test = model_random_forest.predict_proba(features_test)\n",
    "\n",
    "        # selecionando apenas as probabilidades da classe \"1\"\n",
    "        probabilities_test_one = probabilities_test[:, 1]\n",
    "\n",
    "        # calculando o score F1\n",
    "        score_f1 = f1_score(target_test, predicted_test)\n",
    "\n",
    "        # calculando o score ROC AUC\n",
    "        score_roc_auc = roc_auc_score(target_test, probabilities_test_one)\n",
    "\n",
    "        # verificando se essa combinação de est e depth apresentou um score melhor\n",
    "        if score_f1 > best_score_f1:\n",
    "            best_score_f1 = score_f1\n",
    "            best_score_roc_auc = score_roc_auc\n",
    "            best_est = est\n",
    "            best_depth = depth\n",
    "\n",
    "# imprimindo o melhor conjunto de parâmetros\n",
    "print('Melhor est:', best_est)\n",
    "print('Melhor depth:', best_depth)\n",
    "print('Melhor f1 score:', best_score_f1)\n",
    "print('Melhor roc auc score:', best_score_roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaef522",
   "metadata": {},
   "source": [
    "**Conclusão**\n",
    "\n",
    "No início do projeto, realizamos o tratamento dos dados, pré-processamento, escalonamento das características e divisão dos conjuntos de dados. Em seguida, utilizamos três modelos: Regressão Logística, Árvore de Decisão e Floresta Aleatória. Com o objetivo de maximizar o desempenho do modelo, identificamos que a Floresta Aleatória apresentou o melhor resultado, alcançando aproximadamente **F1 score de validação de 0,59 e ROC AUC score de validação de 0,85**, já atingindo a meta estabelecida de *F1 score de pelo menos 0,59*. Dessa forma, decidimos utilizar o modelo de Floresta Aleatória para o restante do projeto.\n",
    "\n",
    "Posteriormente, aplicamos o ajuste de ponderação da classe e treinamos o modelo usando o método upsample. No teste final, superamos nossa meta e obtivemos um resultado aproximado de **F1 score de 0,6279969064191803 e ROC AUC score de 0,851155501652755**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
